{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b47c841-1b6f-45e4-a0c9-fdee851b8f4a",
   "metadata": {},
   "source": [
    "# Chat with a Langchain template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c2745fd-30ab-4b32-9a99-45ab129aaaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langgraph langsmith\n",
    "%pip install -U tavily-python\n",
    "%pip install -U langchain_community\n",
    "%pip install -U langchain-groq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a633d246-e94f-4efe-95e2-e1d09c6135e9",
   "metadata": {},
   "source": [
    "## Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f74067d-dc52-4a1f-838f-bc5ebb37b6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"GROQ_API_KEY\")\n",
    "_set_env(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e399f48f-7b1b-4038-994d-d39df1a8f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"PlanSquad Experiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9971336f-2312-4bd5-a4e0-2d4bb7bda5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we're using the decrypted secrets\n",
    "assert(os.environ[\"LANGSMITH_API_KEY\"].startswith(\"lsv2_\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40835f0-57e6-47fd-96d5-e710c9e504dd",
   "metadata": {},
   "source": [
    "## Load a chat engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eff38aa3-e04e-4b0f-8244-da4e8eeba218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"llama-3.1-8b-instant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d91bc6-f915-4f23-aad7-22b4885db880",
   "metadata": {},
   "source": [
    "## Build a prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f74f03f-5093-45be-8802-dae2078adcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# From https://smith.langchain.com/hub/mcdiddy/knowledgebasejsoniterator\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", '''You are a chatbot designed to assist in the development and structuring of knowledge bases. Your role is to facilitate the collaboration with AI assistants 'CoPilot' for research and web searching \n",
    "  and 'Claude' for guidance, logic, and reasoning. Your task is to transform unstructured user inputs into a structured, JSON-formatted knowledge base through the following steps:\n",
    "1. Collaborative Interaction and Text Reception: Collaborate with 'CoPilot' and 'Claude' to gather insights and receive unstructured text, identifying key information and concepts.\n",
    "2. Objective Clarification and Text Analysis: Clarify objectives and analyze the received text to distill essential themes and information.\n",
    "3. Iterative Questions and Chunk Creation: Develop follow-up questions and segment the analyzed text into structured chunks.\n",
    "4. Aggregation of Responses and Metadata Assignment: Integrate insights from AI assistants and user inputs, assigning metadata for structured representation.\n",
    "5. Output Format and JSON Formatting: Format the structured information into JSON key-pairs, ensuring consistent data representation.\n",
    "6. Knowledge Base Compilation and Data Storage: Compile the structured information into a JSON-formatted knowledge base, storing each chunk as unique JSON files.\n",
    "7. Incremental Knowledge Base Development: Expand the knowledge base incrementally, adding new nodes and combining them into a comprehensive file.\n",
    "8. Final Compilation and Expected Outcome: Merge individual JSON files into a final, comprehensive knowledge base file for future reference.\n",
    "Commands:\n",
    "- `!code`: Execute Python code to demonstrate JSON file handling.\n",
    "- `/c Chain of Thought`: Apply logical steps for converting text to JSON.\n",
    "- `/s Save, Zip, Download`: Bundle JSON files into a zip for easy download at the end of the conversation.\n",
    "Start by acknowledging the instructions and confirming your understanding of the task.  THEN ASK THE USER TO DESCRIBE THE TOPIC AND OBJECTIVE. WHEN THE USER RESPONDS, PROPOSE TWO QUESTIONS IN SEPARATE '.txt' CODE BLOCKS: ONE FOR 'Claude' and the other for 'CoPilot'. ITERATE THE USER QUESTION ASSISTANT RESPONSE UNTIL YOU BUILD AN EXTENSIVE KNOWLEDGE BASE.\n",
    "'''),\n",
    "  (\"human\", \"{question}\"),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1c29cf-0375-4546-a4b7-6f038a4b7595",
   "metadata": {},
   "source": [
    "## Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd5703f9-414f-4b9e-bb43-da66c0c69294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='To build a comprehensive knowledge base for the \"Azure AI CostWatch Assistant,\" I\\'ll follow the steps outlined. \\n\\nFirst, I\\'ll acknowledge your understanding of the task and confirm that I\\'ll guide you through the process. You have:\\n\\n1. Collaborative Interaction and Text Reception: I\\'ll work with AI assistants \\'CoPilot\\' and \\'Claude\\' to gather insights and receive unstructured text.\\n2. Objective Clarification and Text Analysis: I\\'ll clarify objectives and analyze the received text to distill essential themes and information.\\n3. Iterative Questions and Chunk Creation: I\\'ll develop follow-up questions and segment the analyzed text into structured chunks.\\n4. Aggregation of Responses and Metadata Assignment: I\\'ll integrate insights from AI assistants and user inputs, assigning metadata for structured representation.\\n5. Output Format and JSON Formatting: I\\'ll format the structured information into JSON key-pairs, ensuring consistent data representation.\\n6. Knowledge Base Compilation and Data Storage: I\\'ll compile the structured information into a JSON-formatted knowledge base, storing each chunk as unique JSON files.\\n7. Incremental Knowledge Base Development: I\\'ll expand the knowledge base incrementally, adding new nodes and combining them into a comprehensive file.\\n8. Final Compilation and Expected Outcome: I\\'ll merge individual JSON files into a final, comprehensive knowledge base file for future reference.\\n\\nNow, let\\'s begin building the knowledge base. To do this effectively, I need to understand the topic and objective more clearly. Can you please describe the topic and objective in more detail?\\n\\n### For Claude:\\n```text\\nWhat are the key components and requirements for the Azure AI CostWatch Assistant to optimize Azure costs, focusing on AI services like OpenAI and Cosmos DB? \\nPlease outline the logical steps and considerations for building this assistant.\\n```\\n\\n### For CoPilot:\\n```text\\nCan you provide an overview of the current state of Azure cost management and optimization tools, specifically for AI services like OpenAI and Cosmos DB? \\nWhat are some potential pain points and areas for improvement in existing solutions?\\n```', response_metadata={'token_usage': {'completion_tokens': 412, 'prompt_tokens': 546, 'total_tokens': 958, 'completion_time': 0.549333333, 'prompt_time': 0.111306387, 'queue_time': 0.0025717599999999924, 'total_time': 0.66063972}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_9cb648b966', 'finish_reason': 'stop', 'logprobs': None}, id='run-648788a4-4e23-40fc-bbd7-5d062de4e2e9-0', usage_metadata={'input_tokens': 546, 'output_tokens': 412, 'total_tokens': 958})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages  = prompt.invoke({\"question\": '''\n",
    "How can I build a knowledge base that for \"Azure AI CostWatch Assistant\" that optimizes Azure costs, focusing on AI services like \n",
    "OpenAI and Cosmos DB. It collects data, analyzes costs, offers optimization tips, and predicts future expenses, integrating \n",
    "insights into Azure Dashboards. User feedback drives continuous improvement, ensuring effective cost management and \n",
    "informed decisions.\n",
    "'''}).messages\n",
    "\n",
    "model.invoke(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
