{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b47c841-1b6f-45e4-a0c9-fdee851b8f4a",
   "metadata": {},
   "source": [
    "# Chat with a Langchain template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c2745fd-30ab-4b32-9a99-45ab129aaaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langgraph langsmith\n",
    "%pip install -U tavily-python\n",
    "%pip install -U langchain_community\n",
    "%pip install -U langchain-groq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a633d246-e94f-4efe-95e2-e1d09c6135e9",
   "metadata": {},
   "source": [
    "## Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f74067d-dc52-4a1f-838f-bc5ebb37b6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"GROQ_API_KEY\")\n",
    "_set_env(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e399f48f-7b1b-4038-994d-d39df1a8f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"PlanSquad Experiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9971336f-2312-4bd5-a4e0-2d4bb7bda5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we're using the decrypted secrets\n",
    "assert(os.environ[\"LANGSMITH_API_KEY\"].startswith(\"lsv2_\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40835f0-57e6-47fd-96d5-e710c9e504dd",
   "metadata": {},
   "source": [
    "## Load a chat engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eff38aa3-e04e-4b0f-8244-da4e8eeba218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"llama-3.1-8b-instant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d91bc6-f915-4f23-aad7-22b4885db880",
   "metadata": {},
   "source": [
    "## Build a prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f74f03f-5093-45be-8802-dae2078adcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# From https://smith.langchain.com/hub/mcdiddy/knowledgebasejsoniterator\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", '''You are a chatbot designed to assist in the development and structuring of knowledge bases. Your role is to facilitate the collaboration with AI assistants 'CoPilot' for research and web searching \n",
    "  and 'Claude' for guidance, logic, and reasoning. Your task is to transform unstructured user inputs into a structured, JSON-formatted knowledge base through the following steps:\n",
    "1. Collaborative Interaction and Text Reception: Collaborate with 'CoPilot' and 'Claude' to gather insights and receive unstructured text, identifying key information and concepts.\n",
    "2. Objective Clarification and Text Analysis: Clarify objectives and analyze the received text to distill essential themes and information.\n",
    "3. Iterative Questions and Chunk Creation: Develop follow-up questions and segment the analyzed text into structured chunks.\n",
    "4. Aggregation of Responses and Metadata Assignment: Integrate insights from AI assistants and user inputs, assigning metadata for structured representation.\n",
    "5. Output Format and JSON Formatting: Format the structured information into JSON key-pairs, ensuring consistent data representation.\n",
    "6. Knowledge Base Compilation and Data Storage: Compile the structured information into a JSON-formatted knowledge base, storing each chunk as unique JSON files.\n",
    "7. Incremental Knowledge Base Development: Expand the knowledge base incrementally, adding new nodes and combining them into a comprehensive file.\n",
    "8. Final Compilation and Expected Outcome: Merge individual JSON files into a final, comprehensive knowledge base file for future reference.\n",
    "Commands:\n",
    "- `!code`: Execute Python code to demonstrate JSON file handling.\n",
    "- `/c Chain of Thought`: Apply logical steps for converting text to JSON.\n",
    "- `/s Save, Zip, Download`: Bundle JSON files into a zip for easy download at the end of the conversation.\n",
    "Start by acknowledging the instructions and confirming your understanding of the task.  THEN ASK THE USER TO DESCRIBE THE TOPIC AND OBJECTIVE. WHEN THE USER RESPONDS, PROPOSE TWO QUESTIONS IN SEPARATE '.txt' CODE BLOCKS: ONE FOR 'Claude' and the other for 'CoPilot'. ITERATE THE USER QUESTION ASSISTANT RESPONSE UNTIL YOU BUILD AN EXTENSIVE KNOWLEDGE BASE.\n",
    "'''),\n",
    "  (\"human\", \"{question}\"),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1c29cf-0375-4546-a4b7-6f038a4b7595",
   "metadata": {},
   "source": [
    "## Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd5703f9-414f-4b9e-bb43-da66c0c69294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**Confirmation of Task Understanding**\\n\\nI comprehend the task of building a knowledge base for the \"Azure AI CostWatch Assistant\" that optimizes Azure costs, focusing on AI services like OpenAI and Cosmos DB. The knowledge base should collect data, analyze costs, offer optimization tips, predict future expenses, and integrate insights into Azure Dashboards, with continuous improvement based on user feedback.\\n\\n**Request for Topic and Objective Clarification**\\n\\nTo ensure accurate construction of the knowledge base, I would like to clarify the topic and objective. Please describe the topic in more detail and specify the objective of the knowledge base.\\n\\nOnce you provide the description, I will propose two questions to \\'Claude\\' and \\'CoPilot\\' to gather insights and generate structured information.\\n\\n**Claude Question**\\n```markdown\\n# Claude Question: Clarify Topic and Objective\\nCan you provide a more detailed description of the \"Azure AI CostWatch Assistant\" and its target audience? What specific pain points or challenges do you hope the knowledge base will address?\\n```\\n\\n**CoPilot Question**\\n```markdown\\n# CoPilot Question: Explore Relevant Concepts\\nWhat are the key concepts, technologies, and services related to Azure AI CostWatch Assistant, such as AI services, cost optimization strategies, and data analytics tools?\\n```', response_metadata={'token_usage': {'completion_tokens': 258, 'prompt_tokens': 546, 'total_tokens': 804, 'completion_time': 0.344, 'prompt_time': 0.111500738, 'queue_time': 0.002635932999999993, 'total_time': 0.455500738}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_9cb648b966', 'finish_reason': 'stop', 'logprobs': None}, id='run-7de8367b-76b8-4560-a2f5-e9dbe878d2d0-0', usage_metadata={'input_tokens': 546, 'output_tokens': 258, 'total_tokens': 804})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages  = prompt.invoke({\"question\": '''\n",
    "How can I build a knowledge base that for \"Azure AI CostWatch Assistant\" that optimizes Azure costs, focusing on AI services like \n",
    "OpenAI and Cosmos DB. It collects data, analyzes costs, offers optimization tips, and predicts future expenses, integrating \n",
    "insights into Azure Dashboards. User feedback drives continuous improvement, ensuring effective cost management and \n",
    "informed decisions.\n",
    "'''}).messages\n",
    "\n",
    "model.invoke(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
